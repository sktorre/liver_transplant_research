---
title: "Feature Selection"
author: "Sarah Torrence"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F, error = F)

# Box access
library(boxr)
box_auth()

library(janitor)
library(ggplot2)
library(tidyverse)
library(naniar)

#read in data
data <- box_read("930224826408")
```

There are many variables I can remove based on them being intermediary variables to clean other variables or based on domain knowledge or cleanliness, they should not be included. I will first filter out these variables.

 **these variables include... bmi, longitudinal body composition**

```{r}
features <- data %>% select(age, height, weight, ascites_yn,
                he, race, sex, smoker, cit, dri, etiology, meld, acr,
                newmalignancy, surgeryduration, readmissionin30d, readmissionwithin90d,
                infection_90, need_repeat_surgery, vascularcomplicationswithin90days,
                sma00, smi00, vat00, sat00, s_mhu00, v_fhu00, sa_thu00,
                biliarycomplication, copd, htn, dm, cad, ckd, ctd, location_dc,
                dayson_ventpost_lt) 
```

```{r}
str(features)
```

```{r}
convert <- c('ascites_yn', 'he', 'race', 'sex', 'smoker', 'etiology', 'acr',
             'newmalignancy', 'readmissionin30d', 'readmissionwithin90d',
             'infection_90', 'need_repeat_surgery',
             'vascularcomplicationswithin90days', 'biliarycomplication', 'copd', 
             'htn', 'dm', 'cad', 'ckd', 'ctd', 'location_dc')

for (var in convert){
  features[var] <- as.factor(features[[var]])
}
```


## Missingness

My first step in feature selection is to look at the percentage of missing values in each of the possible features. Imputation can be used, but if any features are missing a very large portion of data, they might not be useful in a model.

```{r}
gg_miss_var(features, show_pct=TRUE)
```

Luckily, I am not missing very many observations for any of these variables. The one missing the most is `smi00` but it is only missing ~4.5% of observation which can easily be imputed.

## Redundancy Analysis

I would like to see if any of my variables are redundant, meaning they can easily be explained by other variables. If a variable is easily explained by the other possible features, it would be redundant to use it in a model, especially when I already too many possible features to use for modeling.

```{r}
r <- redun(as.formula(paste0("~ ",paste0(colnames(features),collapse = "+"))), type = 'adjusted', data=features, r2 = .8)

r['rsq1']
r['rsquared']
#r
```

With an adjusted R^2 of 0.99 the variance in height is easily explained by the other variables. This actually makes sense due to the fact that $smi00 = sma00/height$.

```{r}
redun(~ smi00 + height + sma00, type = 'adjusted', data=features, r2 = 0.8)
```

I would rather keep the original measurements in the model rather than derived measurements. Because I know `smi00` based on `height` and `sma00`, I will remove `smi00`.

```{r}
features <- features %>% select(-smi00)
```

Now let's perform the redundancy analysis again to determine whether any other variables are redundant.

```{r}
r2 <- redun(as.formula(paste0("~ ",paste0(colnames(features),collapse = "+"))), type = 'adjusted', data=features, r2 = .8)

r2['rsq1']
r2['rsquared']
#r2
```

There are still some body composition variables with pretty high adjusted R^2 values, meaning their variance can be explained by other variables, but because these are important features in my analysis I want to use them as possible features in my model. During the modeling process, I will do some more analysis to determine which variables are used as predictors, but for now I do not want to exclude any more body composition variables just yet.

## Variable Clustering

Now I will try some variable clustering to see if there are any strong clusters in my variables of interest.

```{r}
vc <- varclus(as.formula(paste0("~ ",paste0(colnames(features),collapse = "+"))), 
              data = features, sim = 'hoeffding')
plot(vc)
```

```{r}
vc2 <- varclus(as.formula(paste0("~ ",paste0(colnames(features),collapse = "+"))), 
              data = features, sim = 'spearman')
plot(vc2)
```

`v_fhu00` and `sa_thu00` cluster together with a high correlation, but these are both important body composition variables in this analysis. `readmissionin30d` and `readmissionwithin90d` are also highly correlated. This makes sense as patients that are readmitted within 30 days of discharge are of course also readmitted within 90 days of discharge. To capture more patients with readmission I will remove `readmissionin30d` and keep `readmissionwithin90d` as a possible feature.

```{r}
features <- features %>% select(-readmissionin30d)
```

Height also seems to be highly correlated with sex. This makes sense as males are usually taller than females. Height can be age-dependent in the elderly, so I want to check if that is the case with this data.

```{r}
d <- datadist(data)
options(datadist="d")
f <- orm(height ~ rcs(age,4)*sex, data = data)
qu <- Quantile(f); med <- function(x) qu(.5, x)
ggplot(Predict(f, age, sex, fun=med, conf.int=FALSE), ylab='Predicted Median Height, cm')
```

For patients younger than 40, there seems to be odd behavior but the average is fairly flat for all patients above 40 meaning there is no relationship with height decreasing in the elderly. At this stage in the process, I think it makes sense to include both height and sex.

## Final features to include in the modeling process

I will save the final list of possible features as a csv for later use in processing the data.

```{r}
#variables required to process data and create outcome (y)
outcome <- c('patient_mrn', 'index_los', 'days_until_death', 'iculos')

#features
feat <- colnames(features)

final_features <- cbind(data[feat],data[outcome])

#box_write(final_features,
#           file_name = "features_selected_stats.csv",
#           dir_id = 159363126194)
```





